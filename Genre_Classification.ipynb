{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genre_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW_A1CtB2sy1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2A_s5BkmbBZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import librosa\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, normalize\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import IPython\n",
        "import math\n",
        "import json\n",
        "from tensorflow.keras import layers, models\n",
        "!pip install ffmpeg gstreamer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6bZC06vS2Cq"
      },
      "source": [
        "# PREDICTING FROM FEATURES GIVEN\n",
        "\n",
        "Referenced from blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwxCCgNg5kLn"
      },
      "source": [
        "os.chdir('/content/gdrive/MyDrive/GTZAN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTvCgCPUpex4"
      },
      "source": [
        "df = pd.read_csv('Data/features_3_sec.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGzPZ0mAE0x-"
      },
      "source": [
        "FEATURE EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIkgHljJE0Sw"
      },
      "source": [
        "#encode y-labels\n",
        "class_list = df.iloc[:,-1]\n",
        "converter = LabelEncoder()\n",
        "y=converter.fit_transform(class_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jdvBJp_GoUr"
      },
      "source": [
        "df =df.drop(labels='filename',axis=1)\n",
        "#to normalize all the x data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "fit = StandardScaler()\n",
        "X = fit.fit_transform(np.array(df.iloc[:,:-1],dtype=float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5aSckDaKW-u"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(len(y_test),len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1NTYpU1KwSi"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
        "input_shape = X_train.shape\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7kuZduWBKZm"
      },
      "source": [
        "best val_acc : 91.44%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2doedtgFuQD-"
      },
      "source": [
        "ANN SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ELtGU-qct19"
      },
      "source": [
        "#ANN for features given\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu',input_shape=(input_shape[1],), name='dense1'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation='relu',name='dense2'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(128, activation='relu',name='dense3'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(64, activation='relu',name='dense4'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "model.fit(X_train.squeeze(axis=2),y_train, validation_data=(X_test, y_test), epochs = 100, batch_size=64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ows_E0kBRMey"
      },
      "source": [
        "# USING AUDIO SIGNALS\n",
        "Referenced from:\n",
        "\n",
        "https://www.youtube.com/watch?v=szyGiObZymo\n",
        "\n",
        "https://www.youtube.com/watch?v=dOG-HxpbMSw\n",
        "\n",
        "Changed the CNN model to use Conv1D instead of 2D, test accuracy improved compared to video by 3%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZiBDN9RS8P"
      },
      "source": [
        "os.chdir('/content/gdrive/MyDrive/GTZAN/Data/genres_original')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci49x59sMwpY"
      },
      "source": [
        "track_dur = 30\n",
        "sample_rate = 22050 ## default, change in librosa.load if changing here and vice versa\n",
        "samples_per_track = sample_rate * track_dur\n",
        "def save_mfcc(n_mfcc= 13, n_fft= 2048,hop_length=512, num_segments=5):\n",
        "  num_samples_per_segment = int(samples_per_track/num_segments)\n",
        "  mfcc_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
        "  data = {\n",
        "      \"mapping\":[],\n",
        "      \"mfcc\":[],\n",
        "      \"labels\":[]\n",
        "  }\n",
        "  for i, (dir,_,filenames) in enumerate(os.walk(os.getcwd())):\n",
        "    if dir == os.getcwd():\n",
        "      data[\"mapping\"]=filenames\n",
        "    else:\n",
        "      label = dir.split('/')[-1]\n",
        "      for f in filenames:\n",
        "        # print('file',f)\n",
        "        file_path = os.path.join(dir,f)\n",
        "        try:\n",
        "          signal,sr = librosa.load(file_path)##can add sample rate here\n",
        "          for s in range(num_segments):\n",
        "            start = s * num_samples_per_segment\n",
        "            end = start + num_samples_per_segment\n",
        "            mfcc = librosa.feature.mfcc(signal[start:end],sr,n_fft=n_fft,n_mfcc=n_mfcc,hop_length=hop_length).T\n",
        "            #ensure same training sample size\n",
        "            if(len(mfcc)== mfcc_per_segment):\n",
        "              data[\"mfcc\"].append(mfcc)\n",
        "              data[\"labels\"].append(i-1)\n",
        "        except:\n",
        "          print('skipping',f)\n",
        "          continue\n",
        "  return data\n",
        "    # json.dump(data,open('/content/gdrive/MyDrive/GTZAN/Data/audio_data.json','w'),indent=4)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtNjgqoInux9"
      },
      "source": [
        "# data = save_mfcc(num_segments=10)\n",
        "# data_json = data.copy()\n",
        "# data_json['mfcc'] = [a.tolist() for a in data_json['mfcc']]\n",
        "# json.dump(data_json,open('/content/gdrive/MyDrive/GTZAN/Data/audio_data.json','w'),indent=4)\n",
        "data = json.load(open('/content/gdrive/MyDrive/GTZAN/Data/audio_data.json','r'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HOleT-BrB3L"
      },
      "source": [
        "X, y = np.array(data[\"mfcc\"]),np.array(data[\"labels\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "# X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "# X_val = X_val.reshape((X_val.shape[0],X_val.shape[1],1))\n",
        "# X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "input_shape = (X_train).shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCbf6BynvVKu"
      },
      "source": [
        "from tensorflow.keras import layers, models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv1D(512, kernel_size=10, activation='relu', input_shape=input_shape[1:],name='conv1'))\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Conv1D(512, kernel_size=5, activation='relu',name='conv2'))\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu',name='conv3'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "filepath = 'audio_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor=’val_accuracy’, verbose=1, save_best_only=True, mode=\"max\")\n",
        "model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks = [checkpoint], epochs = 50, batch_size=64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smiU2nH9xXJ9"
      },
      "source": [
        "model.evaluate(X_test, y_test, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGUg2vsko7oN"
      },
      "source": [
        "# ##best model save\n",
        "# model = models.Sequential()\n",
        "# model.add(layers.Conv1D(512, kernel_size=10, activation='relu', input_shape=input_shape[1:],name='conv1'))\n",
        "# model.add(layers.MaxPooling1D(2))\n",
        "# model.add(layers.Conv1D(512, kernel_size=5, activation='relu',name='conv2'))\n",
        "# model.add(layers.MaxPooling1D(2))\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(256, activation='relu',name='conv3'))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "# model.summary()\n",
        "# model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs = 60, batch_size=64)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}